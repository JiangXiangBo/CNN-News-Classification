{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836075"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1、获取数据\n",
    "# 1.1、获取文件文本路径\n",
    "import os\n",
    "def getFilePathList(rootDir):\n",
    "    filePath_list = []\n",
    "    for walk in os.walk(rootDir):\n",
    "        part_filePath_list = [os.path.join(walk[0], file) for file in walk[2]]\n",
    "        filePath_list.extend(part_filePath_list)\n",
    "    return filePath_list\n",
    "filePath_list = getFilePathList('THUCNews')\n",
    "len(filePath_list)\n",
    "# 文件路径列表中共有836075元素，即在THUCNews文件夹中总共有836075文本文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836075"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2、获取所有的样本标签\n",
    "label_list = []\n",
    "for filePath in filePath_list:\n",
    "    label = filePath.split('\\\\')[1]\n",
    "    label_list.append(label)\n",
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "科技    162929\n",
       "股票    154398\n",
       "体育    131604\n",
       "娱乐     92632\n",
       "时政     63086\n",
       "社会     50849\n",
       "教育     41936\n",
       "财经     37098\n",
       "家居     32586\n",
       "游戏     24373\n",
       "房产     20050\n",
       "时尚     13368\n",
       "彩票      7588\n",
       "星座      3578\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3、标签统计计数\n",
    "import pandas as pd\n",
    "\n",
    "pd.value_counts(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4、调用pickle库保存label_list标签\n",
    "import pickle\n",
    "\n",
    "with open('label_list.pickle', 'wb') as file:\n",
    "    pickle.dump(label_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5、保存所有的样本内容，保存content_list内容\n",
    "# 避免内存溢出，每读取一定数量的文件就利用pickle库的dump方法保存。\n",
    "# 因为有80多万个文本文件，读取时间较长\n",
    "import time\n",
    "import re\n",
    "\n",
    "def getFile(filePath):\n",
    "    with open(filePath, encoding='utf8') as file:\n",
    "        fileStr = ''.join(file.readlines(1000))\n",
    "    return fileStr\n",
    "\n",
    "interval = 20000\n",
    "n_samples = len(label_list)\n",
    "startTime = time.time()\n",
    "directory_name = 'content_list'\n",
    "# if not os.path.isdir(directory_name):\n",
    "#     os.mkdir(directory_name)\n",
    "# for i in range(0, n_samples, interval):\n",
    "#     startIndex = i\n",
    "#     endIndex = i + interval\n",
    "#     content_list = []\n",
    "#     print('%06d-%06d start' %(startIndex, endIndex))\n",
    "#     for filePath in filePath_list[startIndex:endIndex]:\n",
    "#         fileStr = getFile(filePath)\n",
    "#         content = re.sub('\\s+', ' ', fileStr)\n",
    "#         content_list.append(content)\n",
    "#     save_fileName = directory_name + '/%06d-%06d.pickle' %(startIndex, endIndex)\n",
    "#     with open(save_fileName, 'wb') as file:\n",
    "#         pickle.dump(content_list, file)\n",
    "#     used_time = time.time() - startTime\n",
    "#     print('%06d-%06d used time: %.2f seconds' %(startIndex, endIndex, used_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used time: 16.58 seconds\n",
      "length of content_list，mean sample size: 836075\n"
     ]
    }
   ],
   "source": [
    "# 2、加载数据集\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def getFilePathList(rootDir):\n",
    "    filePath_list = []\n",
    "    for walk in os.walk(rootDir):\n",
    "        part_filePath_list = [os.path.join(walk[0], file) for file in walk[2]]\n",
    "        filePath_list.extend(part_filePath_list)\n",
    "    return filePath_list\n",
    "\n",
    "startTime = time.time()\n",
    "contentListPath_list = getFilePathList('content_list')\n",
    "content_list = []\n",
    "for filePath in contentListPath_list:\n",
    "    with open(filePath, 'rb') as file:\n",
    "        part_content_list = pickle.load(file)\n",
    "    content_list.extend(part_content_list)\n",
    "with open('label_list.pickle', 'rb') as file:\n",
    "    label_list = pickle.load(file)\n",
    "used_time = time.time() - startTime\n",
    "print('used time: %.2f seconds' %used_time)\n",
    "sample_size = len(content_list)\n",
    "print('length of content_list，mean sample size: %d' %sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used time: 76.52 seconds\n"
     ]
    }
   ],
   "source": [
    "# 3、词汇表\n",
    "# 3.1 制作词汇表\n",
    "# 内容列表content_list中的元素是每篇文章内容，数据类型为字符串。\n",
    "# 对所有文章内容中的字做统计计数，出现次数排名前10000的字赋值给变量vocabulary_list。\n",
    "from collections import Counter \n",
    "def getVocabularyList(content_list, vocabulary_size):\n",
    "    allContent_str = ''.join(content_list)\n",
    "    counter = Counter(allContent_str)\n",
    "    vocabulary_list = [k[0] for k in counter.most_common(vocabulary_size)]\n",
    "    return ['PAD'] + vocabulary_list\n",
    "startTime = time.time()\n",
    "vocabulary_list = getVocabularyList(content_list, 10000)\n",
    "used_time = time.time() - startTime\n",
    "print('used time: %.2f seconds' %used_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2、保存词汇表\n",
    "import pickle \n",
    "\n",
    "with open('vocabulary_list.pickle', 'wb') as file:\n",
    "    pickle.dump(vocabulary_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1、加载词汇表\n",
    "import pickle\n",
    "with open('vocabulary_list.pickle', 'rb') as file:\n",
    "    vocabulary_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_test_split used time : 5.52 seconds\n"
     ]
    }
   ],
   "source": [
    "# 4.2、数据准备\n",
    "import time\n",
    "startTime = time.time()\n",
    "\n",
    "# 划分训练集、测试集；\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(content_list, label_list)\n",
    "\n",
    "# 训练集文本内容列表train_content_list，训练集标签列表train_label_list，\n",
    "# 测试集文本内容列表test_content_list，测试集标签列表test_label_list\n",
    "train_content_list = train_X\n",
    "train_label_list = train_y\n",
    "test_content_list = test_X\n",
    "test_label_list = test_y\n",
    "used_time = time.time() - startTime\n",
    "print('train_test_split used time : %.2f seconds' %used_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content2idList used time : 158.10 seconds\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 10000  # 词汇表达小\n",
    "sequence_length = 600    # 序列长度\n",
    "embedding_size = 64      # 词向量维度\n",
    "num_filters = 256        # 卷积核数目\n",
    "filter_size = 5          # 卷积核尺寸\n",
    "num_fc_units = 128       # 全连接层神经元\n",
    "dropout_keep_probability = 0.5  # dropout保留比例\n",
    "learning_rate = 1e-3     # 学习率\n",
    "batch_size = 64          # 每批训练大小\n",
    "\n",
    "# 使用列表推导式得到词汇及其id对应的列表，并调用dict方法将列表强制转换为字典。\n",
    "word2id_dict = dict([(b, a) for a, b in enumerate(vocabulary_list)])\n",
    "# 打印变量word2id_dict的前5项\n",
    "list(word2id_dict.items())[:5]\n",
    "\n",
    "# 使用列表推导式和匿名函数定义函数content2idlist，函数作用是将文章中的每个字转换为id\n",
    "content2idList = lambda content : [word2id_dict[word] for word in content if word in word2id_dict]\n",
    "# 使用列表推导式得到的结果是列表的列表，\n",
    "# 总列表train_idlist_list中的元素是每篇文章中的字对应的id列表；\n",
    "train_idlist_list = [content2idList(content) for content in train_content_list]\n",
    "used_time = time.time() - startTime\n",
    "print('content2idList used time : %.2f seconds' %used_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program\\ANACONDA\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data preparation used time : 974.35 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 新闻类别是14种，\n",
    "num_classes = np.unique(label_list).shape[0]\n",
    "\n",
    "# 获得能够用于模型训练的特征矩阵和预测目标值；\n",
    "import tensorflow.contrib.keras as kr\n",
    "# 每个样本统一长度为seq_length，即600\n",
    "train_X = kr.preprocessing.sequence.pad_sequences(train_idlist_list, sequence_length)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "# 调用LabelEncoder对象的fit_transform方法做标签编码；\n",
    "# 调用keras.untils库的to_categorical方法将标签编码的结果再做Ont-Hot编码。\n",
    "train_y = labelEncoder.fit_transform(train_label_list)\n",
    "train_Y = kr.utils.to_categorical(train_y, num_classes)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "# 数据占位符准备\n",
    "X_holder = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y_holder = tf.placeholder(tf.float32, [None, num_classes])\n",
    "used_time = time.time() - startTime\n",
    "print('data preparation used time : %.2f seconds' %used_time)\n",
    "\n",
    "\"\"\"\n",
    "代码进行到此步，python进程占用6个多G内存，如下图所示。\n",
    "所以此项目需要较高的机器配置，如果电脑内存不足可以通过下面2种方法解决：\n",
    "1.购买内存条提高机器配置，本文作者建议使用此方式，省心省力。\n",
    "2.将阶段性结果保存在本地，重启python，读取阶段性结果。\n",
    "3.不一次性处理全部样本，样本分批处理好之后再汇总。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5、搭建神经网络\n",
    "# 可以更新的模型参数embedding，矩阵形状为vocab_size*embedding_size，即5000*64；\n",
    "embedding = tf.get_variable('embedding', [vocabulary_size, embedding_size])\n",
    "# 调用tf.nn库的embedding_lookup方法将输入数据做词嵌入，\n",
    "# embedding_inputs的形状为batch_size*sequence_length*embedding_size，即64*600*64\n",
    "embedding_inputs = tf.nn.embedding_lookup(embedding, X_holder)\n",
    "\n",
    "# 第1个参数是输入数据，第2个参数是卷积核数量num_filters，\n",
    "# 第3个参数是卷积核大小filter_size。\n",
    "# 方法结果赋值给变量conv，形状为batch_size*596*num_filters，596是600-5+1的结果\n",
    "conv = tf.layers.conv1d(embedding_inputs, num_filters, filter_size)\n",
    "# 变量conv的第1个维度做求最大值操作。\n",
    "# 方法结果赋值给变量max_pooling，形状为batch_size*num_filters，即64*256\n",
    "max_pooling = tf.reduce_max(conv, [1])\n",
    "\n",
    "# 全连接层1，方法结果赋值给变量full_connect，\n",
    "# 形状为batch_size*num_fc_units，即64*128；\n",
    "full_connect = tf.layers.dense(max_pooling,\n",
    "                               num_fc_units)\n",
    "# dropout\n",
    "full_connect_dropout = tf.contrib.layers.dropout(full_connect, \n",
    "                                                 keep_prob=dropout_keep_probability)\n",
    "full_connect_activate = tf.nn.relu(full_connect_dropout)\n",
    "\n",
    "# 全连接层2，结果赋值给变量softmax_before，\n",
    "# 形状为batch_size*num_classes，即64*14\n",
    "softmax_before = tf.layers.dense(full_connect_activate,\n",
    "                                 num_classes)\n",
    "# softmax预测概率值\n",
    "predict_Y = tf.nn.softmax(softmax_before)\n",
    "# 交叉熵损失\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y_holder,\n",
    "                                                         logits=softmax_before)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "# 优化器\"Adam\"\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "isCorrect = tf.equal(tf.argmax(Y_holder, 1), tf.argmax(predict_Y, 1))\n",
    "# 准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(isCorrect, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6、参数初始化\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:200 loss:1.0776 accuracy:0.6550\n",
      "step:400 loss:0.7222 accuracy:0.8000\n",
      "step:600 loss:0.6368 accuracy:0.8150\n",
      "step:800 loss:0.6312 accuracy:0.8000\n",
      "step:1000 loss:0.5845 accuracy:0.8000\n",
      "step:1200 loss:0.3116 accuracy:0.8900\n",
      "step:1400 loss:0.5037 accuracy:0.9100\n",
      "step:1600 loss:0.3861 accuracy:0.8750\n",
      "step:1800 loss:0.4050 accuracy:0.8750\n",
      "step:2000 loss:0.2139 accuracy:0.9400\n",
      "step:2200 loss:0.2312 accuracy:0.9300\n",
      "step:2400 loss:0.3798 accuracy:0.8850\n",
      "step:2600 loss:0.3414 accuracy:0.9100\n",
      "step:2800 loss:0.3760 accuracy:0.9000\n",
      "step:3000 loss:0.3499 accuracy:0.9000\n",
      "step:3200 loss:0.4085 accuracy:0.8750\n",
      "step:3400 loss:0.3402 accuracy:0.9200\n",
      "step:3600 loss:0.4457 accuracy:0.8900\n",
      "step:3800 loss:0.2511 accuracy:0.9250\n",
      "step:4000 loss:0.2418 accuracy:0.9450\n",
      "step:4200 loss:0.3237 accuracy:0.9150\n",
      "step:4400 loss:0.4114 accuracy:0.8900\n",
      "step:4600 loss:0.3292 accuracy:0.9200\n",
      "step:4800 loss:0.3570 accuracy:0.8900\n",
      "step:5000 loss:0.3737 accuracy:0.8850\n",
      "step:5200 loss:0.3446 accuracy:0.9100\n",
      "step:5400 loss:0.3031 accuracy:0.9050\n",
      "step:5600 loss:0.2320 accuracy:0.9350\n",
      "step:5800 loss:0.1941 accuracy:0.9350\n",
      "step:6000 loss:0.2551 accuracy:0.9300\n",
      "step:6200 loss:0.2439 accuracy:0.9150\n",
      "step:6400 loss:0.3196 accuracy:0.9000\n",
      "step:6600 loss:0.3389 accuracy:0.9100\n",
      "step:6800 loss:0.2769 accuracy:0.9300\n",
      "step:7000 loss:0.1922 accuracy:0.9300\n",
      "step:7200 loss:0.2638 accuracy:0.9200\n",
      "step:7400 loss:0.2872 accuracy:0.9250\n",
      "step:7600 loss:0.2608 accuracy:0.9150\n",
      "step:7800 loss:0.2795 accuracy:0.9200\n",
      "step:8000 loss:0.3508 accuracy:0.9000\n",
      "step:8200 loss:0.2909 accuracy:0.9100\n",
      "step:8400 loss:0.3178 accuracy:0.8900\n",
      "step:8600 loss:0.4132 accuracy:0.8900\n",
      "step:8800 loss:0.2753 accuracy:0.9050\n",
      "step:9000 loss:0.1606 accuracy:0.9500\n",
      "step:9200 loss:0.1906 accuracy:0.9400\n",
      "step:9400 loss:0.3169 accuracy:0.9050\n",
      "step:9600 loss:0.3765 accuracy:0.9300\n",
      "step:9800 loss:0.3564 accuracy:0.8950\n",
      "step:10000 loss:0.3589 accuracy:0.9200\n",
      "step:10200 loss:0.2183 accuracy:0.9300\n",
      "step:10400 loss:0.3007 accuracy:0.8950\n",
      "step:10600 loss:0.3168 accuracy:0.9150\n",
      "step:10800 loss:0.2884 accuracy:0.9150\n",
      "step:11000 loss:0.2389 accuracy:0.9250\n",
      "step:11200 loss:0.2405 accuracy:0.9450\n",
      "step:11400 loss:0.4553 accuracy:0.8700\n",
      "step:11600 loss:0.2388 accuracy:0.9100\n",
      "step:11800 loss:0.2234 accuracy:0.9200\n",
      "step:12000 loss:0.1930 accuracy:0.9300\n",
      "step:12200 loss:0.2784 accuracy:0.9100\n",
      "step:12400 loss:0.2762 accuracy:0.9250\n",
      "step:12600 loss:0.1523 accuracy:0.9500\n",
      "step:12800 loss:0.2627 accuracy:0.9250\n",
      "step:13000 loss:0.2271 accuracy:0.9000\n",
      "step:13200 loss:0.2346 accuracy:0.9400\n",
      "step:13400 loss:0.2719 accuracy:0.9300\n",
      "step:13600 loss:0.3814 accuracy:0.9000\n",
      "step:13800 loss:0.2950 accuracy:0.9000\n",
      "step:14000 loss:0.1570 accuracy:0.9400\n",
      "step:14200 loss:0.2281 accuracy:0.9450\n",
      "step:14400 loss:0.2569 accuracy:0.9300\n",
      "step:14600 loss:0.2417 accuracy:0.9200\n",
      "step:14800 loss:0.3256 accuracy:0.9200\n",
      "step:15000 loss:0.3738 accuracy:0.9400\n",
      "step:15200 loss:0.2234 accuracy:0.9300\n",
      "step:15400 loss:0.3472 accuracy:0.9100\n",
      "step:15600 loss:0.2125 accuracy:0.9450\n",
      "step:15800 loss:0.2433 accuracy:0.9300\n",
      "step:16000 loss:0.3004 accuracy:0.9250\n",
      "step:16200 loss:0.3360 accuracy:0.9250\n",
      "step:16400 loss:0.1918 accuracy:0.9500\n",
      "step:16600 loss:0.1664 accuracy:0.9500\n",
      "step:16800 loss:0.2655 accuracy:0.9300\n",
      "step:17000 loss:0.2909 accuracy:0.9000\n",
      "step:17200 loss:0.4154 accuracy:0.9100\n",
      "step:17400 loss:0.2355 accuracy:0.9200\n",
      "step:17600 loss:0.2625 accuracy:0.9000\n",
      "step:17800 loss:0.2629 accuracy:0.9250\n",
      "step:18000 loss:0.1821 accuracy:0.9350\n",
      "step:18200 loss:0.1460 accuracy:0.9600\n",
      "step:18400 loss:0.2433 accuracy:0.9300\n",
      "step:18600 loss:0.2378 accuracy:0.9150\n",
      "step:18800 loss:0.1726 accuracy:0.9550\n",
      "step:19000 loss:0.3138 accuracy:0.9450\n",
      "step:19200 loss:0.2202 accuracy:0.9350\n",
      "step:19400 loss:0.3922 accuracy:0.8900\n",
      "step:19600 loss:0.2780 accuracy:0.9250\n",
      "step:19800 loss:0.2010 accuracy:0.9550\n",
      "step:20000 loss:0.2952 accuracy:0.9300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model/text_model'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7、模型训练\n",
    "# 获取测试集中的数据\n",
    "test_idlist_list = [content2idList(content) for content in test_content_list]\n",
    "test_X = kr.preprocessing.sequence.pad_sequences(test_idlist_list, sequence_length)\n",
    "test_y = labelEncoder.transform(test_label_list)\n",
    "test_Y = kr.utils.to_categorical(test_y, num_classes)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "import random\n",
    "for i in range(20000):\n",
    "    # 从训练集中选取batch_size大小，即64个样本做批量梯度下降\n",
    "    selected_index = random.sample(list(range(len(train_y))), k=batch_size)\n",
    "    batch_X = train_X[selected_index]\n",
    "    batch_Y = train_Y[selected_index]\n",
    "    session.run(train, {X_holder:batch_X, Y_holder:batch_Y})\n",
    "    \n",
    "    step = i + 1 \n",
    "    if step % 200 == 0:\n",
    "        # 从测试集中随机选取200个样本\n",
    "        selected_index = random.sample(list(range(len(test_y))), k=200)\n",
    "        batch_X = test_X[selected_index]\n",
    "        batch_Y = test_Y[selected_index]\n",
    "        # 计算损失值loss_value、准确率accuracy_value\n",
    "        loss_value, accuracy_value = session.run([loss, accuracy], {X_holder:batch_X, Y_holder:batch_Y})\n",
    "        print('step:%d loss:%.4f accuracy:%.4f' %(step, loss_value, accuracy_value))\n",
    "\n",
    "# 模型保存\n",
    "saver.save(session, \"model/text_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program\\ANACONDA\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>体育</th>\n",
       "      <th>娱乐</th>\n",
       "      <th>家居</th>\n",
       "      <th>彩票</th>\n",
       "      <th>房产</th>\n",
       "      <th>教育</th>\n",
       "      <th>时尚</th>\n",
       "      <th>时政</th>\n",
       "      <th>星座</th>\n",
       "      <th>游戏</th>\n",
       "      <th>社会</th>\n",
       "      <th>科技</th>\n",
       "      <th>股票</th>\n",
       "      <th>财经</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>体育</th>\n",
       "      <td>32582</td>\n",
       "      <td>114</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>娱乐</th>\n",
       "      <td>361</td>\n",
       "      <td>21747</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "      <td>94</td>\n",
       "      <td>114</td>\n",
       "      <td>18</td>\n",
       "      <td>70</td>\n",
       "      <td>200</td>\n",
       "      <td>261</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>家居</th>\n",
       "      <td>41</td>\n",
       "      <td>121</td>\n",
       "      <td>7467</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>24</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>202</td>\n",
       "      <td>61</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>彩票</th>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1666</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>房产</th>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>4648</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>137</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>教育</th>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>9661</td>\n",
       "      <td>27</td>\n",
       "      <td>174</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>302</td>\n",
       "      <td>168</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>时尚</th>\n",
       "      <td>23</td>\n",
       "      <td>115</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2933</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>时政</th>\n",
       "      <td>144</td>\n",
       "      <td>86</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>141</td>\n",
       "      <td>30</td>\n",
       "      <td>14005</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>276</td>\n",
       "      <td>442</td>\n",
       "      <td>340</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>星座</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>736</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>游戏</th>\n",
       "      <td>41</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5322</td>\n",
       "      <td>19</td>\n",
       "      <td>572</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>社会</th>\n",
       "      <td>123</td>\n",
       "      <td>248</td>\n",
       "      <td>52</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>266</td>\n",
       "      <td>32</td>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>10671</td>\n",
       "      <td>556</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>科技</th>\n",
       "      <td>103</td>\n",
       "      <td>208</td>\n",
       "      <td>177</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>123</td>\n",
       "      <td>43</td>\n",
       "      <td>388</td>\n",
       "      <td>1</td>\n",
       "      <td>278</td>\n",
       "      <td>432</td>\n",
       "      <td>38373</td>\n",
       "      <td>585</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>股票</th>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>104</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>43</td>\n",
       "      <td>917</td>\n",
       "      <td>36316</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>财经</th>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>119</td>\n",
       "      <td>186</td>\n",
       "      <td>1212</td>\n",
       "      <td>7592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       体育     娱乐    家居    彩票    房产    教育    时尚     时政   星座    游戏     社会  \\\n",
       "体育  32582    114    10    27     4    10    17     53    2    11     31   \n",
       "娱乐    361  21747    54     0     9    61    94    114   18    70    200   \n",
       "家居     41    121  7467     0    61    24    94     41   19    16     41   \n",
       "彩票    190      1     1  1666     0     3     0      0    4     1     27   \n",
       "房产     20     22    75     0  4648    11     2     30    1     2     53   \n",
       "教育     65     77    38    16    16  9661    27    174   16    21    302   \n",
       "时尚     23    115    76     2     1    10  2933     15   12    21     28   \n",
       "时政    144     86    29     5    41   141    30  14005    1     8    276   \n",
       "星座      5     30    12     3     4    17    39      8  736    13      8   \n",
       "游戏     41     46     6     4     2    11    25     13    6  5322     19   \n",
       "社会    123    248    52    61    60   266    32    482    0    14  10671   \n",
       "科技    103    208   177     7    21   123    43    388    1   278    432   \n",
       "股票     15     45    54     6   104    16     8    400    3    19     43   \n",
       "财经     19     24    30    11    43     8     9     73    3     3    119   \n",
       "\n",
       "       科技     股票    财经  \n",
       "体育     45     10     0  \n",
       "娱乐    261     32     3  \n",
       "家居    202     61    15  \n",
       "彩票      7      6     1  \n",
       "房产     52    137    38  \n",
       "教育    168     47    10  \n",
       "时尚     49      5     0  \n",
       "时政    442    340    51  \n",
       "星座      5      2     3  \n",
       "游戏    572      6     0  \n",
       "社会    556     32    38  \n",
       "科技  38373    585    61  \n",
       "股票    917  36316   680  \n",
       "财经    186   1212  7592  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8、混淆矩阵\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def predictAll(test_X, batch_size=100):\n",
    "    predict_value_list = []\n",
    "    for i in range(0, len(test_X), batch_size):\n",
    "        selected_X = test_X[i: i + batch_size]\n",
    "        predict_value = session.run(predict_Y, {X_holder:selected_X})\n",
    "        predict_value_list.extend(predict_value)\n",
    "    return np.array(predict_value_list)\n",
    "\n",
    "Y = predictAll(test_X)\n",
    "y = np.argmax(Y, axis=1)\n",
    "predict_label_list = labelEncoder.inverse_transform(y)\n",
    "pd.DataFrame(confusion_matrix(test_label_list, predict_label_list), \n",
    "             columns=labelEncoder.classes_,\n",
    "             index=labelEncoder.classes_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>体育</td>\n",
       "      <td>0.965908</td>\n",
       "      <td>0.989853</td>\n",
       "      <td>0.977734</td>\n",
       "      <td>32916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>娱乐</td>\n",
       "      <td>0.950315</td>\n",
       "      <td>0.944536</td>\n",
       "      <td>0.947417</td>\n",
       "      <td>23024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>家居</td>\n",
       "      <td>0.924019</td>\n",
       "      <td>0.910277</td>\n",
       "      <td>0.917097</td>\n",
       "      <td>8203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>彩票</td>\n",
       "      <td>0.921460</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.896904</td>\n",
       "      <td>1907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>房产</td>\n",
       "      <td>0.927004</td>\n",
       "      <td>0.912984</td>\n",
       "      <td>0.919941</td>\n",
       "      <td>5091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>教育</td>\n",
       "      <td>0.932349</td>\n",
       "      <td>0.908159</td>\n",
       "      <td>0.920095</td>\n",
       "      <td>10638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>时尚</td>\n",
       "      <td>0.874739</td>\n",
       "      <td>0.891489</td>\n",
       "      <td>0.883035</td>\n",
       "      <td>3290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>时政</td>\n",
       "      <td>0.886617</td>\n",
       "      <td>0.897814</td>\n",
       "      <td>0.892180</td>\n",
       "      <td>15599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>星座</td>\n",
       "      <td>0.895377</td>\n",
       "      <td>0.831638</td>\n",
       "      <td>0.862332</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>游戏</td>\n",
       "      <td>0.917744</td>\n",
       "      <td>0.876338</td>\n",
       "      <td>0.896563</td>\n",
       "      <td>6073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>社会</td>\n",
       "      <td>0.871102</td>\n",
       "      <td>0.844559</td>\n",
       "      <td>0.857625</td>\n",
       "      <td>12635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>科技</td>\n",
       "      <td>0.917246</td>\n",
       "      <td>0.940515</td>\n",
       "      <td>0.928735</td>\n",
       "      <td>40800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>股票</td>\n",
       "      <td>0.936197</td>\n",
       "      <td>0.940196</td>\n",
       "      <td>0.938192</td>\n",
       "      <td>38626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>财经</td>\n",
       "      <td>0.894018</td>\n",
       "      <td>0.813545</td>\n",
       "      <td>0.851885</td>\n",
       "      <td>9332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>总体</td>\n",
       "      <td>0.926505</td>\n",
       "      <td>0.926801</td>\n",
       "      <td>0.926463</td>\n",
       "      <td>209019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label  Precision    Recall        F1  Support\n",
       "0      体育   0.965908  0.989853  0.977734    32916\n",
       "1      娱乐   0.950315  0.944536  0.947417    23024\n",
       "2      家居   0.924019  0.910277  0.917097     8203\n",
       "3      彩票   0.921460  0.873623  0.896904     1907\n",
       "4      房产   0.927004  0.912984  0.919941     5091\n",
       "5      教育   0.932349  0.908159  0.920095    10638\n",
       "6      时尚   0.874739  0.891489  0.883035     3290\n",
       "7      时政   0.886617  0.897814  0.892180    15599\n",
       "8      星座   0.895377  0.831638  0.862332      885\n",
       "9      游戏   0.917744  0.876338  0.896563     6073\n",
       "10     社会   0.871102  0.844559  0.857625    12635\n",
       "11     科技   0.917246  0.940515  0.928735    40800\n",
       "12     股票   0.936197  0.940196  0.938192    38626\n",
       "13     财经   0.894018  0.813545  0.851885     9332\n",
       "999    总体   0.926505  0.926801  0.926463   209019"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9.报告表\n",
    "# 此段代码主要是调用sklearn.metrics库的precision_recall_fscore_support方法得出报告表。\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def eval_model(y_true, y_pred, labels):\n",
    "    # 计算每个分类的Precision, Recall, f1, support\n",
    "    p, r, f1, s = precision_recall_fscore_support(y_true, y_pred)\n",
    "    # 计算总体的平均Precision, Recall, f1, support\n",
    "    tot_p = np.average(p, weights=s)\n",
    "    tot_r = np.average(r, weights=s)\n",
    "    tot_f1 = np.average(f1, weights=s)\n",
    "    tot_s = np.sum(s)\n",
    "    res1 = pd.DataFrame({\n",
    "        u'Label': labels,\n",
    "        u'Precision': p,\n",
    "        u'Recall': r,\n",
    "        u'F1': f1,\n",
    "        u'Support': s\n",
    "    })\n",
    "    res2 = pd.DataFrame({\n",
    "        u'Label': ['总体'],\n",
    "        u'Precision': [tot_p],\n",
    "        u'Recall': [tot_r],\n",
    "        u'F1': [tot_f1],\n",
    "        u'Support': [tot_s]\n",
    "    })\n",
    "    res2.index = [999]\n",
    "    res = pd.concat([res1, res2])\n",
    "    return res[['Label', 'Precision', 'Recall', 'F1', 'Support']]\n",
    "\n",
    "eval_model(test_label_list, predict_label_list, labelEncoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.总结\n",
    "1.数据共有80多万条。\n",
    "2.分类模型的评估指标F1score为0.93左右，总体来说这个分类模型比较优秀，能够投入实际应用。\n",
    "3.因为本项目工程量较大，后续优化工作可以从解决样本不均衡问题开展，使用下采样或下采样方法。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
